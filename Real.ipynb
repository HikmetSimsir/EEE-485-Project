{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Neural Network (MLP) Algorithm for Yeast Data\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor, ceil, sqrt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparation of the Data\n",
    "### Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def the_train_test_split(X, test_ratio = 0.2):\n",
    "    if(test_ratio >= 1 or test_ratio <0):\n",
    "        test_ratio = 0.2\n",
    "    row, _ = X.shape\n",
    "    train_count = floor(row * (1-test_ratio))\n",
    "    train = X[:train_count]\n",
    "    test = X[train_count:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"yeast.csv\"\n",
    "md = pd.read_csv(file_name)\n",
    "\n",
    "# md.dropna(inplace = True)\n",
    "# md.replace('unknown', 0, inplace = True)\n",
    "md.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Prepare the data\n",
    "* Shuffle the data\n",
    "* Separate the input and output variables\n",
    "* Seperate the data into training and test sets\n",
    "* Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gl = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shuffle the data to get more fair representative\n",
    "md.reindex(np.random.permutation(md.index))\n",
    "\n",
    "test_ratio = 0.2\n",
    "X = md.values[:,1:9]\n",
    "Y = md.values[:,9:]\n",
    "cat = pd.unique(Y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(X.shape[1]):\n",
    "    X[:,i] = (X[:,i] - X[:,i].mean())/X[:,i].std()\n",
    "\n",
    "\n",
    "#\n",
    "y = np.zeros((len(Y), 10))\n",
    "for i in range(len(Y)):\n",
    "    for j in range(10):\n",
    "        if cat[j] == Y[i]:\n",
    "            y[i][j] = 1\n",
    "        else:\n",
    "            y[i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test = the_train_test_split(X.astype(\"float64\"), test_ratio = test_ratio)\n",
    "Y_train, Y_test = the_train_test_split(y.astype(\"float64\"), test_ratio = test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self, dimension=[100,100], epochs=100, learning_rate=0.001, act_func = \"sigmoid\"):\n",
    "        self.dim = dimension\n",
    "        self.ep = epochs\n",
    "        self.lr = learning_rate\n",
    "        # weight 0: input to 1st hidden\n",
    "        # weight 1:  1st hidden to  2nd hidden\n",
    "        # weight len(dim): last hidden to output\n",
    "        # in total 1+len(dim) weight matrices\n",
    "        self.weights = {} # they will be defined when the input and output are given\n",
    "\n",
    "        # actv 0: fired from input layer\n",
    "        # actv 1: fired from 1st layer\n",
    "        # actv 1+len(dim): fired from output layer\n",
    "        self.actv = {} # activation outputs\n",
    "        # z 0: input to 1st hidden\n",
    "        # z 1:  1st hidden to  2nd hidden\n",
    "        # z len(dim): last hidden to output\n",
    "        # in total 1+len(dim) weight matrices\n",
    "        self.z = {} # middle values: inputs to next layers\n",
    "    def forward(self, x):\n",
    "        self.actv[0] = x\n",
    "        for i in range(len(self.dim)+1):\n",
    "            #print(\"forward actv[\",i,\"] : \",self.actv[i])\n",
    "\n",
    "            self.z[i] = np.dot(self.weights[i], self.actv[i])\n",
    "            #print(\"forward z[\",i,\"] : \",self.z[i])\n",
    "\n",
    "            if i == len(self.dim):\n",
    "                self.actv[i+1] = self.actFunc(self.z[i], \"soft\" )\n",
    "            else:\n",
    "                self.actv[i+1] = self.actFunc(self.z[i], \"sigm\" )\n",
    "            #print(\"forward actv[\",i+1,\"] : \",self.actv[i+1], \"#\")\n",
    "        return self.actv[1+len(self.dim)]\n",
    "\n",
    "    def actFunc(self, t, type=\"sigm\"):\n",
    "        if type == \"sigm\":\n",
    "            return self.sigm(t)\n",
    "        elif type==\"sigm-d\":\n",
    "            return self.sigm(t,True)\n",
    "        elif type==\"soft\":\n",
    "            return self.softmax(t)\n",
    "        else:\n",
    "            return self.sigm(t)\n",
    "\n",
    "    def sigm(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        exps = np.exp(x - x.max())\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def back_prop(self, y_exp, y_pred):\n",
    "        err = y_pred-y_exp\n",
    "        w_chng = {}\n",
    "        dimlen = len(self.dim)\n",
    "        # calculate the update for the last weights\n",
    "        w_chng[dimlen]= np.multiply(err, self.actv[1+dimlen])\n",
    "        # calculate changes backwardly\n",
    "        for i in range(dimlen):\n",
    "            # e.g. the 1st weights (i.e. w[0])\n",
    "            # will be updated when i := dimlen-1\n",
    "            # so that err depends on w[1], previous err and z[0]\n",
    "            # and change depends on a[1]\n",
    "            err = np.multiply( np.dot(self.weights[dimlen-i].T, err), self.actFunc(self.z[dimlen-i-1], \"sigm-d\"))\n",
    "            w_chng[dimlen-i-1] = np.dot(err, self.actv[dimlen-i])\n",
    "        #print(\"w_chng: \", type(w_chng), \" : \", w_chng)\n",
    "        return w_chng\n",
    "\n",
    "    def update_weights(self, w_changes):\n",
    "        # why calling items() https://stackoverflow.com/a/62173039/13555389\n",
    "        global gl\n",
    "        gl[\"w_changes\"] = w_changes\n",
    "        gl['wc'] = {}\n",
    "        for i, chng in w_changes.items():\n",
    "            for k in range( len(self.weights[i].T)):\n",
    "                self.weights[i].T[k] = self.weights[i].T[k] -    self.lr*chng\n",
    "                gl['wc'][k] =- self.lr*chng\n",
    "                #w_mtrx = w_mtrx - self.lr*chng\n",
    "\n",
    "    # THE FOLLOWING FUNCTION IS COPIED IN VERBATIM\n",
    "    def get_accuracy(self, x_val, y_val):\n",
    "        self.pred_indices = np.empty([y_val.shape[0], 2], \"int\" )\n",
    "        print(\"p_i shape:\",self.pred_indices.shape)\n",
    "        global gl\n",
    "        predictions = []\n",
    "        i = 0\n",
    "        for x, y in zip(x_val, y_val):\n",
    "            output = self.forward(x)\n",
    "            pred = np.argmax(output)\n",
    "            exp = np.argmax(y)\n",
    "            self.pred_indices[i][0], self.pred_indices[i][1]= pred, exp\n",
    "            #print(output, \" : \", pred, \" :: \", y, \" : \", exp)\n",
    "            predictions.append(pred == exp)\n",
    "            i = i+1\n",
    "\n",
    "        #summed = sum(pred for pred in predictions) / 100.0\n",
    "\n",
    "        gl['p'] = predictions\n",
    "        gl['p_i'] = self.pred_indices\n",
    "        return sum(pred for pred in gl['p'])/len(gl['p'])#np.average(summed)\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test):\n",
    "        # initialize weights! etc.!\n",
    "        # we seperate 1st and last because they depend on the size of x_train and y_train, respectively!\n",
    "        # weights from input to 1st hidden\n",
    "        self.weights[0] = np.random.randn(self.dim[0], x_train.shape[1]) * np.sqrt(1. / self.dim[0])\n",
    "        # set default weights to middle layer weights if there any\n",
    "        dimlen = len(self.dim)\n",
    "        for i in range(dimlen - 1):\n",
    "            self.weights[i+1] = np.random.randn(self.dim[i+1], self.dim[i]) * np.sqrt(1. / self.dim[i+1])\n",
    "            #print(\"train: \" ,i+1, type( self.weights[i+1]))\n",
    "        # last weights\n",
    "        self.weights[dimlen] = np.random.randn(y_train.shape[1], self.dim[dimlen-1]) * np.sqrt(1. / y_train.shape[1])\n",
    "        #print(\"train: \" ,dimlen, type( self.weights[dimlen]))\n",
    "\n",
    "\n",
    "    # train them all\n",
    "        start_time = time.time()\n",
    "        print(\"Started training!\")\n",
    "        for iteration in range(self.ep):\n",
    "            for x,y in zip(x_train, y_train):\n",
    "                #print(\"In the inner loop!\")\n",
    "                output = self.forward(x)\n",
    "\n",
    "                changes_to_w = self.back_prop(y, output)\n",
    "                self.update_weights(changes_to_w)\n",
    "\n",
    "            accuracy = self.get_accuracy(x_test, y_test)\n",
    "            print('{0}th epoch, {1:.2f} seconds wasted so far, for merely {2}  accuracy'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xor_x= np.array([ [0, 0],\n",
    "     [1, 0],\n",
    "     [0, 1],\n",
    "     [1, 1]\n",
    "     ])\n",
    "#xor_y =np.array( [ [0], [1], [1],[0]])\n",
    "xor_y =np.array( [ [1, 0], [0,1], [0,1],[1,0]])\n",
    "\n",
    "dnn = Neural_Network(dimension=[ 15, 15 ], epochs=100, learning_rate=0.1)\n",
    "dnn.train(xor_x, xor_y, xor_x, xor_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gl['p']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(sum(pred for pred in gl['p']) )\n",
    "print(len(gl['p']))\n",
    "print(sum(pred for pred in gl['p'])/len(gl['p']))\n",
    "summed = sum(pred for pred in gl['p']) / 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dnn = Neural_Network(dimension=[ 15, 20 ], epochs=100, learning_rate=0.1)\n",
    "dnn.train(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print(gl)\n",
    "for i, j in gl[\"w_changes\"].items():\n",
    "    print(\"i: \", i, \", j: \", j)\n",
    "\n",
    "gl['wc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(dnn.get_accuracy(X_test, Y_test))\n",
    "print(dnn.get_accuracy(X_train, Y_train))\n",
    "print(Y_test.shape[0])\n",
    "pred_class = cat[gl['p_i'][:,0]]\n",
    "exp_class = cat[gl['p_i'][:,1]]\n",
    "print(exp_class)\n",
    "ConfusionMatrixDisplay.from_predictions(exp_class, pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range (3):\n",
    "    print(\"type z[\",i,\"] : \", type(dnn.z[i]))\n",
    "    print(\"shape z[\",i,\"] : \",dnn.z[i].shape)\n",
    "    #print(\"forward z[\",i,\"] : \",dnn.z[i])\n",
    "    print(\"\")\n",
    "    print(\"type actv[\",i,\"] : \", type(dnn.actv[i]))\n",
    "    print(\"shape actv[\",i,\"] : \",dnn.actv[i].shape)\n",
    "    #print(\"forward actv[\",i,\"] : \",dnn.actv[i])\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"type weights[\",i,\"] : \", type(dnn.weights[i]))\n",
    "    print(\"shape weights[\",i,\"] : \",dnn.weights[i].shape)\n",
    "    #print(\"forward weights[\",i,\"] : \",dnn.weights[i])\n",
    "    print(\"-----------------\\n\")\n",
    "\n",
    "i = 3\n",
    "print(\"type actv[\",i,\"] : \", type(dnn.actv[i]))\n",
    "print(\"shape actv[\",i,\"] : \",dnn.actv[i].shape)\n",
    "print(\"forward actv[\",i,\"] : \",dnn.actv[i])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(type(dnn.weights[0]) ) #, \", shape: \"dnn.weights[0].shape)\n",
    "print(type(dnn.weights[1]) ) #, \", shape: \"dnn.weights[1].shape)\n",
    "print(type(dnn.weights[2]) ) #, \", shape: \"dnn.weights[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dnn.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dnn.weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dnn.weights[2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b647197a1fcc38d756609367937b3918f8af3cc96749ff11478d444b1db53c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
