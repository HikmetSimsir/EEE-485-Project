{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm for Yeast Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "from math import floor, ceil, sqrt\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_train_test_split(X, test_ratio = 0.2):\n",
    "    if(test_ratio >= 1 or test_ratio <0):\n",
    "        test_ratio = 0.2\n",
    "    row, _ = X.shape\n",
    "    train_count = floor(row * (1-test_ratio)) \n",
    "    train = X[:train_count]\n",
    "    test = X[train_count:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x,y):\n",
    "    return sqrt(sum(np.square(x-y)))\n",
    "\n",
    "def minkowski_distance(x,y):\n",
    "    return -1;\n",
    "\n",
    "def get_distance(x, y, algorithm =\"euclidean\"):\n",
    "    if(algorithm == \"euclidean\"):\n",
    "        return euclidean_distance(x,y)\n",
    "    else:\n",
    "        print(\"The algorithm \", algorithm, \" couldn't be recognized.\\n\", \"\\\"euclidean\\\" algorithm is used instead\")\n",
    "        return euclidean_distance(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Neigbours_Classifier():\n",
    "    def __init__(self, neigbour_count = 7, algorithm = \"euclidean\"):\n",
    "        self.alg = algorithm\n",
    "        self.n_count = neigbour_count\n",
    "\n",
    "    def fit(self, train_input, train_output):\n",
    "        self.train_in = train_input\n",
    "        self.train_out = train_output\n",
    "        #\n",
    "        pd.unique(self.train_out) # since it is array of arrays sized 1\n",
    "        self.categories = pd.unique(self.train_out.ravel())\n",
    "    \n",
    "    def predict(self, single):\n",
    "        # calculate the distances\n",
    "        distances = np.apply_along_axis(get_distance, 1, self.train_in, y=single, algorithm=self.alg)\n",
    "        #print(distances)\n",
    "        nearest_indices = np.argpartition(distances, self.n_count)[:self.n_count]\n",
    "        #print(nearest_indices)\n",
    "        category_dict = dict.fromkeys(self.categories, 0)\n",
    "        nearest_keys = self.train_out[nearest_indices]\n",
    "        for neigbour_key in nearest_keys:\n",
    "            category_dict[neigbour_key] = 1 + category_dict[neigbour_key]\n",
    "        the_key_with_max = max(category_dict, key=category_dict.get)\n",
    "        #print(\"We predict this one to be: \", the_key_with_max)\n",
    "        return the_key_with_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(X_train, Y_train, X_test, Y_test  ):\n",
    "    knc = K_Neigbours_Classifier(neigbour_count=13)\n",
    "    knc.fit(X_train, Y_train[:,0]) # we know that y_train is 1 dimensional \n",
    "    correct_pred = 0\n",
    "    incorrect_pred = 0\n",
    "    correct_pred_dict = dict.fromkeys(cat,0)\n",
    "    failed_to_pred_dict = dict.fromkeys(cat,0)\n",
    "    assumed_to_pred_dict = dict.fromkeys(cat,0)\n",
    "\n",
    "    predictions = [] #= np.empty(Y_test.size,  dtype=\"S3\")\n",
    "    for i in range (Y_test.size):\n",
    "        correct_key = Y_test[i][0]\n",
    "        predicted_key =knc.predict(X_test[i])\n",
    "        predictions.append(predicted_key)\n",
    "        if(  predicted_key== correct_key):\n",
    "            correct_pred = 1 + correct_pred\n",
    "            correct_pred_dict[correct_key] = 1 + correct_pred_dict[correct_key]\n",
    "\n",
    "        else:\n",
    "            incorrect_pred = 1 + incorrect_pred\n",
    "            failed_to_pred_dict[correct_key] = 1 + failed_to_pred_dict[correct_key]\n",
    "            assumed_to_pred_dict[predicted_key] = 1 + assumed_to_pred_dict[predicted_key] \n",
    "            \n",
    "    print(\"Accuracy: \", correct_pred/(correct_pred + incorrect_pred) )\n",
    "    print(\"Number of correct predictions: \", correct_pred)\n",
    "    print(\"Number of incorrect predictions: \", incorrect_pred)\n",
    "    print(\"correct predict(ion) count:\\n\", correct_pred_dict)\n",
    "    print(\"failed_to predict(ion) count:\\n\", failed_to_pred_dict)\n",
    "    print(\"assumed_to predict(ion) count:\\n\", assumed_to_pred_dict)\n",
    "    \n",
    "\n",
    "    print(\"\\n                   Classification Report                  \\n\",\n",
    "    classification_report(Y_test,predictions, zero_division=1)) # ignores zero division warning\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"yeast.csv\" \n",
    "md = pd.read_csv(file_name)\n",
    "\n",
    "# md.dropna(inplace = True)\n",
    "# md.replace('unknown', 0, inplace = True)\n",
    "md.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "* Separate the input and output variables\n",
    "* Seperate the data into training and test sets\n",
    "* Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.2\n",
    "X = md.values[:,1:9]\n",
    "Y = md.values[:,9:]\n",
    "cat = pd.unique(Y[:,0])\n",
    "\n",
    "# normalize X:\n",
    "for i in range(X.shape[1]):\n",
    "    X[:,i] = (X[:,i] - X[:,i].mean())/X[:,i].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = the_train_test_split(X, test_ratio = test_ratio)\n",
    "Y_train, Y_test = the_train_test_split(Y, test_ratio = test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA pretest VIA Sci-Kit LEARN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=7)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test = the_train_test_split(X, test_ratio = test_ratio)\n",
    "Y_train, Y_test = the_train_test_split(Y, test_ratio = test_ratio)\n",
    "\n",
    "measure(X_train, Y_train, X_test, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c3aa14960646f8382bb681c4fca9f05f8fb10aa6e0ffd3a01e7a92b428a8bd9e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
